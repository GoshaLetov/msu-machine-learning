{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54862117",
   "metadata": {},
   "source": [
    "# 5.1. Параметры\n",
    "\n",
    "Ваша задача - обучить классификатор на стандартном датасете Ирисов Фишера решать задачу предсказания сорта цветка по описанию 4 его параметров.\n",
    "\n",
    "Ваша задача - дополнить приведённый ниже код таким образом, чтобы конфигурация обучения была следующей:\n",
    "\n",
    "1) В тренировочную выборку должно быть включено 60% всех объектов, выбранных из датасета случайным образом (поскольку датасет очень простой для обучения модели, 60% тренировочных объектов более, чем достаточно)\n",
    "\n",
    "2) Максимальная глубина построенного дерева не должна превышать 3\n",
    "\n",
    "3) В качестве критерия ветвления используйте критерий Джини\n",
    "\n",
    "4) Random state и random seed установите равными 42\n",
    "\n",
    "В качестве ответа к задаче укажите оценку качества классификации на тестовой выборке при помощи accuracy_score. Ответ округлите **вниз** до сотых. Разделитель дробной и целой части в ответе - **точка**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443dfcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Импортируйте необходимые классы и функции из соответствующих модулей sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.6, random_state=42)\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(x_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, preds), 2)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ac518",
   "metadata": {},
   "source": [
    "# 5.2. Лучшая комбинация\n",
    "\n",
    "Ваша задача - обучить стандартный регрессор на основе решающего дерева решать задачу предсказания стоимости бриллианта по набору его признаков, к которым относятся: * Число карат * Цвет * Чистота * Геометрические размеры и т.п.\n",
    "\n",
    "Датасет можно загрузить по [ссылке](https://drive.google.com/drive/u/0/folders/1CAjs-yQQfHFrAAsX9dy_hXGIyc7wx0CH).\n",
    "\n",
    "Датасет необходимо предобработать следующим образом:\n",
    "* Удалить ненужную колонку, дублирующую индекс;\n",
    "* Преобразовать все данные к числовому типу (если это необходимо);\n",
    "* Воспользуйтесь One-hot encoder для преобразования категориальных признаков.\n",
    "* Перемешайте выборку при помощи функции sklearn.utils.shuffle с random_state=42.\n",
    "\n",
    "Категориальными признаками в нашем случае служат признаки \"cut\", \"color\" и \"clarity\".\n",
    "\n",
    "Более правильный способ сделать это - воспользоваться классом 'sklearn.preprocessing.LabelEncoder', подробности в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Мы рекомендуем воспользоваться именно LabelEncoder.\n",
    "\n",
    "Выберите лучшую комбинацию гиперпараметров из предложенных:\n",
    "* Критерий ветвления: squared_error, глубина дерева: 12\n",
    "* Критерий ветвления: friedman_mse, глубина дерева: 16\n",
    "* Критерий ветвления: poisson, глубина дерева: 22\n",
    "* Критерий ветвления: squared_error, глубина дерева: 45\n",
    "* Критерий ветвления: friedman_mse, глубина дерева: 95\n",
    "* Критерий ветвления: poisson, глубина дерева: 33\n",
    "\n",
    "Лучшим будет тот критерий, который покажет наилучшее среднее качество с точки зрения метрики $R^2$ при кроссвалидации с CV=10. Random state и random seed установите равными 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9307536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a00965",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423aa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/goshaletov/Documents/Study/Master/Trimester1/MachineLearning/Homeworks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee663a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Homework 5/TRAIN.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942505f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cut = LabelEncoder()\n",
    "encoder_color = LabelEncoder()\n",
    "encoder_clarity = LabelEncoder()\n",
    "\n",
    "df['cut'] = encoder_cut.fit_transform(df['cut'])\n",
    "df['color'] = encoder_cut.fit_transform(df['color'])\n",
    "df['clarity'] = encoder_cut.fit_transform(df['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5112acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944df791",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.price.values\n",
    "X = df.drop('price', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f8a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_set = [\n",
    "    {'criterion': 'squared_error', 'max_depth': 12},\n",
    "    {'criterion': 'friedman_mse', 'max_depth': 16},\n",
    "    {'criterion': 'poisson', 'max_depth': 22},\n",
    "    {'criterion': 'squared_error', 'max_depth': 45},\n",
    "    {'criterion': 'friedman_mse', 'max_depth': 95},\n",
    "    {'criterion': 'poisson', 'max_depth': 33},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45964a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in params_set:\n",
    "    reg = DecisionTreeRegressor(random_state=42, **params)\n",
    "    params['score'] = cross_val_score(reg, X, y, scoring='r2', cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd2412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'squared_error', 'max_depth': 12, 'score': 0.974376370315037}\n"
     ]
    }
   ],
   "source": [
    "print(max(params_set, key=lambda x: x['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4d313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
