{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a72a62c",
   "metadata": {},
   "source": [
    "# 7.1. F1-measure\n",
    "\n",
    "На [лекции](https://colab.research.google.com/drive/12xpYdqi1S4y68FYHym2rZ3wzHSm8cSLm?usp=sharing) мы подробно обсудили, что доля правильных ответов - не самая лучшая метрика оценки качества классификации. Довольно часто доля правильных ответов даёт смещенную оценку качества и способна ввести в заблуждение. По этой причине мы пользуемся метриками качества, которые называются *точностью* и *полнотой*, а также их комбинацией - *F1-мерой*. Ваша задача - реализовать функции `precision`, `recall` и `f1`. На вход всех этих функий подаются два вектора: `y_true`: вектор правильных ответов и `y_pred`: вектор предсказаний.\n",
    "\n",
    "В рамках выполнения этого задания можно использовать только модуль `numpy`.\n",
    "\n",
    "**Замечание:** проверить себя Вы можете, сравнив свои ответы с функциями `sklearn.metrics.precision_score`, `sklearn.metrics.recall_score` и `sklearn.metrics.f1_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48dda972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    TP = y_pred[y_true == y_pred].sum()\n",
    "    FP = y_pred[y_true != y_pred].sum()\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    TP = y_pred[y_true == y_pred].sum()\n",
    "    FN = - (y_pred[y_true != y_pred] - 1).sum()\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision_socre = precision(y_true, y_pred)\n",
    "    recall_score = recall(y_true, y_pred)\n",
    "    return 2 * (precision_socre * recall_score) / (precision_socre + recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd419a",
   "metadata": {},
   "source": [
    "# 7.2. Площади\n",
    "\n",
    "Мы предлагаем вам решить задачу бинарной классификации на датасете breast_cancer при помощи 4 различных алгоритмов:\n",
    "* Decision Tree (1)\n",
    "* Logistic Regression (2)\n",
    "* KNN (3)\n",
    "* SVC (4)\n",
    "\n",
    "Ваша задача - найти алгоритмы с наилучшими показателями ROC AUC score и PR AUC score. В качестве ответа укажите число ab, где a - лучший с точки зрения ROC AUC score алгоритм, а b - лучший с точки зрения PR AUC score алгоритм.\n",
    "\n",
    "Например, ответ 43 будет интерпретирован следующим образом: Алгоритм 4 (SVM) оказался лучшим с точки зрения roc_auc_score, а алгоритм 3 (KNN) - с точки зрения pr_auc_score.\n",
    "\n",
    "В качестве параметров выбирайте параметры по умолчанию. Для KNN выберете k=5. Random State установите равным 42. Разбиение на train и test проведите с параметром test_size=0.3.\n",
    "\n",
    "Не забудьте провести дополнительную предобработку данных, приведя их к единой шкале при помощи StandardScaler.\n",
    "Примеры вычисления обеих метрик были предложены на лекции.\n",
    "\n",
    "В этой задаче Вам требуется сравнить значения метрик для 4 различных алгоритмов. Для этого отредактируйте следующий код так, чтобы он соответствовал сформулированному заданию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd25f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "estimators = [tree, lr, knn, svm]\n",
    "\n",
    "roc_scores = []\n",
    "pr_scores = []\n",
    "for estimator in estimators:\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_score = estimator.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    \n",
    "    roc = roc_auc_score(y_test, y_score)        \n",
    "    pr = auc(recall, precision)\n",
    "    \n",
    "    roc_scores.append(roc)\n",
    "    pr_scores.append(pr)\n",
    "    \n",
    "print(np.argmax(roc_scores) + 1, np.argmax(pr_scores) + 1, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcd925",
   "metadata": {},
   "source": [
    "# 7.3. Усреднение\n",
    "\n",
    "Ваша задача в этом задании - написать функции для реализации микро и макро усреднения метрик при многоклассовой классификации. Прочитать про концепции микро- и макроусреднений можно в [лекции 7](https://colab.research.google.com/drive/12xpYdqi1S4y68FYHym2rZ3wzHSm8cSLm#scrollTo=RGxp4ftIBbfG). \n",
    "\n",
    "Заполните тела функций:\n",
    "\n",
    "* `err_table` для составления матрицы ошибок для многоклассового случая\n",
    "* `micro_precision` для микроусреднения точности\n",
    "* `macro_precision` для макроусреднения точности\n",
    "* `micro_recall` для микроусреднения полноты\n",
    "* `macro_recall` для макроусреднения полноты\n",
    "* `micro_f1` для микроусреднения f1-меры\n",
    "* `macro_f1` для макроусреднения f1-меры\n",
    "\n",
    "В рамках решения этого задания можно пользоваться только фреймворком `numpy`\n",
    "\n",
    "*Напоминание:*\n",
    "\n",
    "Микроусреднение подразумевает вычисление совокупной усреднённой матрицы ошибок по всем k бинарным классификациям, каждая из которых отделяет i-й класс от всех остальных. Затем по этой усредненной матрице вычисляется необходимая метрика.\n",
    "\n",
    "То есть, если мы считаем некоторую функцию $f(a_i, b_i)$, где $a_i, b_i$ - величины, определённые для каждой из k задач классификации, то в случае микроусреднения мы посчитаем значение $\\bar{f} = f(\\bar{a}, \\bar{b})$, где значком $\\bar{}$ обозначено среднее значение.\n",
    "\n",
    " Макроусреднение же предполагает вычисление k независимых метрик для каждой задачи бинарной классификации, и лишь затем мы усредняем эти значения.\n",
    " \n",
    " То есть мы должны посчитать набор значений $f_i = f(a_i, b_i)$, а затем усреднить $\\bar{f} = \\frac{1}{k}Σf_i$\n",
    "___________________________\n",
    "**Замечание:**\n",
    "Мы гарантируем, что в y_true представлены все возможные классы, то есть при составлении таблицы err_table можно ориентироваться на число классов в y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2e43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def err_table(y_true: np.array, y_pred: np.array):\n",
    "    \"\"\"\n",
    "    В рамках этой функции Вы должны составить матрицу ошибок предсказаний для многоклассовой классификации\n",
    "    Строки этой матрицы будут символизировать истинные классы, а столбцы - предсказанные.\n",
    "    Например, число N в ячейке матрицы ij будет интерпретировано следующим образом: \n",
    "      - Данный алгоритм классификации классифицировал N объектов, относящихся к классу i, как объекты класса j\n",
    "    \n",
    "    Замечание:\n",
    "        Функция, выполняющая такую задачу реализована в sklearn.metrics, называется confusion_matrix. \n",
    "        В Вашей будущей работе мы рекомендуем пользоваться именно ей. Однако в рамках выполнения этого задания \n",
    "        запрещено использование функций из sklearn\n",
    "\n",
    "    Аргументы:\n",
    "        - y_true - массив правильных ответов\n",
    "        - y_pred - массив предсказанных классов\n",
    "    \"\"\"\n",
    "    classes = np.sort(np.unique(y_true))\n",
    "    confusion_matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    for i in classes:\n",
    "        for j in classes:\n",
    "            y_pred_j = y_true[y_pred == j]\n",
    "            y_pred_j_i = y_pred_j[y_pred_j == i]\n",
    "            confusion_matrix[i, j] = len(y_pred_j_i)\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def micro_precision(err_table: np.array):\n",
    "    TP = np.diag(err_table)\n",
    "    FP = err_table.sum(axis=0) - TP\n",
    "    return TP.mean() / (TP.mean() + FP.mean())\n",
    "\n",
    "def macro_precision(err_table: np.array):\n",
    "    TP = np.diag(err_table)\n",
    "    FP = err_table.sum(axis=0) - TP\n",
    "    return (TP / (TP + FP)).mean()\n",
    "\n",
    "def micro_recall(err_table: np.array):\n",
    "    TP = np.diag(err_table)\n",
    "    FN = err_table.sum(axis=1) - TP\n",
    "    return TP.mean() / (TP.mean() + FN.mean())\n",
    "\n",
    "def macro_recall(err_table: np.array):\n",
    "    TP = np.diag(err_table)\n",
    "    FN = err_table.sum(axis=1) - TP\n",
    "    return (TP / (TP + FN)).mean()\n",
    "\n",
    "def micro_f1(err_table: np.array):\n",
    "    TP = np.diag(err_table)\n",
    "    FP = err_table.sum(axis=0) - TP\n",
    "    FN = err_table.sum(axis=1) - TP\n",
    "    precision = TP.mean() / (TP.mean() + FP.mean())\n",
    "    recall = TP.mean() / (TP.mean() + FN.mean())\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "def macro_f1(err_table: np.array):\n",
    "    TP = np.diag(err_table)\n",
    "    FP = err_table.sum(axis=0) - TP\n",
    "    FN = err_table.sum(axis=1) - TP\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    return (2 * precision * recall / (precision + recall)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6a7258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 0],\n",
       "       [3, 1, 0],\n",
       "       [1, 1, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])\n",
    "y_pred = np.array([0, 0, 1, 1, 0, 1, 0, 0, 2, 1, 0, 2])\n",
    "err_ = err_table(y_true, y_pred)\n",
    "err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9556a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "0.5277777777777778\n",
      "0.4166666666666667\n",
      "0.4166666666666667\n",
      "0.4166666666666667\n",
      "0.4388888888888889\n"
     ]
    }
   ],
   "source": [
    "print(micro_precision(err_))\n",
    "print(macro_precision(err_))\n",
    "print(micro_recall(err_))\n",
    "print(macro_recall(err_))\n",
    "print(micro_f1(err_))\n",
    "print(macro_f1(err_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35992d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
