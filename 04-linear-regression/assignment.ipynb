{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4128b66c",
   "metadata": {},
   "source": [
    "# 4.1 Линейная регрессия\n",
    "\n",
    "Вам предложен шаблон класса LinearRegression. Реализуйте методы  .fit() и .predict() соответствующие изложенной выше модели. В рамках выполнения этого задания можно пользоваться только библиотекой numpy. Использование любых других библиотек приведёт к ошибке при проверке задания автоматизированной системой. Также мы просим Вас не менять название класса и обозначенных методов, это также приведёт к ошибке. Добавлять свои методы в класс можно.\n",
    "\n",
    "Полученные коэффициенты модели должны храниться в поле .coef_\n",
    "\n",
    "\n",
    "Шаблон класса LinearRegression приведён ниже. Заполните все необходимые пропуски и отправьте получившийся файл в яндекс.контест. Не забудьте про все необходимые импорты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f5230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.coef_: np.array\n",
    "        \n",
    "    @staticmethod\n",
    "    def _add_intercept(x: np.array) -> np.array:\n",
    "        if len(x.shape) == 1:\n",
    "            x = x[:, np.newaxis]\n",
    "        return np.hstack([x, np.ones((x.shape[0], 1))])\n",
    "\n",
    "    def fit(self, x: np.array, y: np.array) -> None:\n",
    "        x = self._add_intercept(x)\n",
    "        self.coef_ = np.matmul(np.matmul(np.linalg.inv(np.matmul(x.T, x)), x.T), y)\n",
    "\n",
    "    def predict(self, x: np.array):\n",
    "        x = self._add_intercept(x)\n",
    "        return np.dot(x, self.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563db16",
   "metadata": {},
   "source": [
    "# 4.2. R-квадрат\n",
    "\n",
    "Одна из метрик оценки качества регрессии - это коэффициент детерминации, или, т.н. R-квадрат. $R^2$ вычисляется по следующей формуле:\n",
    "\n",
    "$$R^2 = 1 - \\frac{D\\epsilon}{Dy}$$\n",
    "\n",
    "где $D\\epsilon$ - это дисперсия ошибки модели, а $Dy$ - это дисперсия зависимой величины y, которую мы пытаемся предсказать.\n",
    "\n",
    "Подробнее об этой метрике можно прочитать в [лекции](https://colab.research.google.com/drive/1MhWrDx0RsNrt4DWsk583Xb-CAm6z27s8#scrollTo=sLSOa0Y49LEz).\n",
    "\n",
    "Вам предлагается написать функцию r2(y_true, y_pred) для подсчета коэффициента детерминации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6e389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def r2(y_true: np.array, y_pred: np.array) -> float:\n",
    "    TSS = sum((y_true - y_true.mean()) ** 2)\n",
    "    ESS = sum((y_true - y_pred) ** 2)\n",
    "    return 1 - ESS / TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0c8fd",
   "metadata": {},
   "source": [
    "# 4.3. Оценка выборки\n",
    "\n",
    "Метрику $R^2$ можно применять также для оценки свойств выборки. Способность линейной модели предсказывать значения с большой долей объясненной дисперсии (что соответствует большому значению $R^2$) говорит о достаточности предложенных нами признаков для моделирования метки. В каком-то смысле, можно рассмотреть 3 случая:\n",
    "1) Предложенные нами признаки x (факторы) позволяют достаточно хорошо обосновать (предсказать) то или иное значение зависимой переменной (метки y), эта зависимость линейная.\n",
    "2) Предложенные нами признаки x позволяют достаточно хорошо обосновать то или иное значение зависимой переменной, но эта зависимость нелинейная.\n",
    "3) Предложенные нами признаки x не позволяют достаточно хорошо обосновать наблюдаемое значение зависимой переменной.\n",
    "\n",
    "Во 2 и 3 случаях, при попытке моделирования выборки линейной моделью мы получим плохое (маленькое) значение $R^2$, хотя причины этого будут немного отличаться. А вот в 1 случае значение $R^2$ будет достаточно большим.\n",
    "\n",
    "Ваша задача среди предложенных Вам 5 выборок найти наилучшую и наихудшую с точки зрения моделирования линейной регрессией (то есть необходимо построить линейную регрессию, посчитать её $R^2$, и найти лучшую и худшую с точки зрения $R^2$ выборки). В ответе в Яндекс.Контест необходимо указать двузначное число, где первая цифра отвечает номеру наилучшей, а вторая - наихудшей из предложенных выборок. Файл имеет следующую структуру: в нем записан массив размером N x 2. Первый столбец представляет признаковое описание объектов, а второй - это значение метки.\n",
    "\n",
    "Например, ответ 32 будет интерпретирован следующим образом: 3 - наилучшая выборка, а 2 - наихудшая.\n",
    "Загрузить данные можно по [ссылке](https://drive.google.com/drive/folders/1uh-2EfVLugYMxUTcB_pDWVbSI5gngRA0?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ca661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.chdir('/Users/goshaletov/Documents/Study/Master/Trimester1/MachineLearning/Homeworks')\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.coef_: np.array\n",
    "        \n",
    "    @staticmethod\n",
    "    def _add_intercept(x: np.array) -> np.array:\n",
    "        if len(x.shape) == 1:\n",
    "            x = x[:, np.newaxis]\n",
    "        return np.hstack([x, np.ones((x.shape[0], 1))])\n",
    "\n",
    "    def fit(self, x: np.array, y: np.array) -> None:\n",
    "        x = self._add_intercept(x)\n",
    "        self.coef_ = np.matmul(np.matmul(np.linalg.inv(np.matmul(x.T, x)), x.T), y)\n",
    "\n",
    "    def predict(self, x: np.array):\n",
    "        x = self._add_intercept(x)\n",
    "        return np.dot(x, self.coef_)\n",
    "\n",
    "\n",
    "def r2(y_true: np.array, y_pred: np.array) -> float:\n",
    "    TSS = sum((y_true - y_true.mean()) ** 2)\n",
    "    ESS = sum((y_true - y_pred) ** 2)\n",
    "    return 1 - ESS / TSS    \n",
    "\n",
    "\n",
    "def main():\n",
    "    container = []\n",
    "\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    for dirpath, _, filenames in os.walk('data/Homework 3'):\n",
    "        for idx, filename in enumerate(sorted(filenames)):\n",
    "            data = np.load(os.path.join(dirpath, filename))\n",
    "            x, y = data[:, 0], data[:, 1]\n",
    "            reg.fit(x, y)\n",
    "            R2 = r2(y, reg.predict(x))\n",
    "            container.append(R2)\n",
    "\n",
    "    container = np.array(container)\n",
    "\n",
    "    print(np.argmax(container) + 1, np.argmin(container) + 1, sep='')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5a432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
